{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Image Classification with CNNs**\n",
        "*   **Objective:** Build and train a CNN to classify images from a dataset such as CIFAR-10 or ImageNet, etc.\n",
        "*   **Key Concepts:** CNN architecture, data augmentation, transfer learning\n"
      ],
      "metadata": {
        "id": "dCp35bm0oZB7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jGAPOTpHbTxW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras import layers, models, datasets\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2, ResNet50\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "LLRnIfd9bVmV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "645c41aa-26ab-4a63-c401-8cfbe81f106d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "VL_HhdwlbZdq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to one-hot encoding\n",
        "train_labels = to_categorical(train_labels, num_classes=10)\n",
        "test_labels = to_categorical(test_labels, num_classes=10)"
      ],
      "metadata": {
        "id": "F0bcYtC7bbOL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "datagen.fit(train_images)"
      ],
      "metadata": {
        "id": "UJZ8hmrLpIQy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained VGG16 model for transfer learning\n",
        "base_model = tf.keras.applications.VGG16(input_shape=(32, 32, 3),\n",
        "                                         include_top=False,\n",
        "                                         weights='imagenet')\n",
        "\n",
        "# Summary of the pre-trained model\n",
        "base_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06Qu58b2b5fa",
        "outputId": "9b8d8fa9-0dba-4db5-cfbb-b527d8c13017"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14714688 (56.13 MB)\n",
            "Trainable params: 14714688 (56.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model-1**"
      ],
      "metadata": {
        "id": "nImeMfe0wt3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the last few layers of the base model\n",
        "for layer in base_model.layers[:-4]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Define the model architecture\n",
        "model1 = models.Sequential([\n",
        "    base_model,\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTY-PWpOpb2i",
        "outputId": "16fcff9e-955d-4856-bd28-a8be5024b6da"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 1, 1, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 512)               2048      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 256)               1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 128)               512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15146442 (57.78 MB)\n",
            "Trainable params: 7509386 (28.65 MB)\n",
            "Non-trainable params: 7637056 (29.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model1.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks\n",
        "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
        "\n",
        "# Train the model with data augmentation\n",
        "history = model1.fit(datagen.flow(train_images, train_labels, batch_size=64),\n",
        "                    steps_per_epoch=len(train_images) / 64,\n",
        "                    epochs=30,\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    callbacks=[checkpoint, reduce_lr])\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model1.evaluate(test_images, test_labels)\n",
        "\n",
        "print(f\"Test Accuracy: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qpgj47ZxpmC0",
        "outputId": "9cc417f5-884a-4e96-c1cc-cb87fdd4438b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "782/781 [==============================] - ETA: 0s - loss: 2.3032 - accuracy: 0.1015\n",
            "Epoch 1: val_accuracy improved from -inf to 0.10000, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r781/781 [==============================] - 42s 49ms/step - loss: 2.3032 - accuracy: 0.1015 - val_loss: 2.3028 - val_accuracy: 0.1000 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "781/781 [============================>.] - ETA: 0s - loss: 2.1463 - accuracy: 0.1774\n",
            "Epoch 2: val_accuracy improved from 0.10000 to 0.21900, saving model to best_model.h5\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 2.1457 - accuracy: 0.1776 - val_loss: 2.8224 - val_accuracy: 0.2190 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "782/781 [==============================] - ETA: 0s - loss: 1.5205 - accuracy: 0.4240\n",
            "Epoch 3: val_accuracy improved from 0.21900 to 0.50420, saving model to best_model.h5\n",
            "781/781 [==============================] - 39s 49ms/step - loss: 1.5205 - accuracy: 0.4240 - val_loss: 1.3698 - val_accuracy: 0.5042 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "781/781 [============================>.] - ETA: 0s - loss: 1.3077 - accuracy: 0.5201\n",
            "Epoch 4: val_accuracy improved from 0.50420 to 0.58960, saving model to best_model.h5\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 1.3073 - accuracy: 0.5202 - val_loss: 1.1741 - val_accuracy: 0.5896 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "781/781 [============================>.] - ETA: 0s - loss: 1.1788 - accuracy: 0.5908\n",
            "Epoch 5: val_accuracy improved from 0.58960 to 0.60410, saving model to best_model.h5\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 1.1785 - accuracy: 0.5909 - val_loss: 1.1443 - val_accuracy: 0.6041 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "782/781 [==============================] - ETA: 0s - loss: 1.1207 - accuracy: 0.6154\n",
            "Epoch 6: val_accuracy improved from 0.60410 to 0.61590, saving model to best_model.h5\n",
            "781/781 [==============================] - 39s 49ms/step - loss: 1.1207 - accuracy: 0.6154 - val_loss: 1.1804 - val_accuracy: 0.6159 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "781/781 [============================>.] - ETA: 0s - loss: 1.0625 - accuracy: 0.6390\n",
            "Epoch 7: val_accuracy improved from 0.61590 to 0.68870, saving model to best_model.h5\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 1.0627 - accuracy: 0.6390 - val_loss: 0.9119 - val_accuracy: 0.6887 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "781/781 [============================>.] - ETA: 0s - loss: 1.0220 - accuracy: 0.6568\n",
            "Epoch 8: val_accuracy did not improve from 0.68870\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 1.0219 - accuracy: 0.6568 - val_loss: 0.9362 - val_accuracy: 0.6884 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "781/781 [============================>.] - ETA: 0s - loss: 0.9897 - accuracy: 0.6686\n",
            "Epoch 9: val_accuracy improved from 0.68870 to 0.69440, saving model to best_model.h5\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.9897 - accuracy: 0.6686 - val_loss: 0.9096 - val_accuracy: 0.6944 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "781/781 [============================>.] - ETA: 0s - loss: 0.9619 - accuracy: 0.6787\n",
            "Epoch 10: val_accuracy improved from 0.69440 to 0.71060, saving model to best_model.h5\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.9619 - accuracy: 0.6788 - val_loss: 0.8574 - val_accuracy: 0.7106 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "781/781 [============================>.] - ETA: 0s - loss: 0.9337 - accuracy: 0.6887\n",
            "Epoch 11: val_accuracy did not improve from 0.71060\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.9337 - accuracy: 0.6887 - val_loss: 0.8441 - val_accuracy: 0.7099 - lr: 0.0010\n",
            "Epoch 12/30\n",
            "782/781 [==============================] - ETA: 0s - loss: 0.9149 - accuracy: 0.6932\n",
            "Epoch 12: val_accuracy did not improve from 0.71060\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.9149 - accuracy: 0.6932 - val_loss: 0.9144 - val_accuracy: 0.7001 - lr: 0.0010\n",
            "Epoch 13/30\n",
            "782/781 [==============================] - ETA: 0s - loss: 0.8927 - accuracy: 0.7038\n",
            "Epoch 13: val_accuracy improved from 0.71060 to 0.74070, saving model to best_model.h5\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.8927 - accuracy: 0.7038 - val_loss: 0.7740 - val_accuracy: 0.7407 - lr: 0.0010\n",
            "Epoch 14/30\n",
            "782/781 [==============================] - ETA: 0s - loss: 0.8730 - accuracy: 0.7112\n",
            "Epoch 14: val_accuracy did not improve from 0.74070\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.8730 - accuracy: 0.7112 - val_loss: 0.8186 - val_accuracy: 0.7204 - lr: 0.0010\n",
            "Epoch 15/30\n",
            "782/781 [==============================] - ETA: 0s - loss: 0.8587 - accuracy: 0.7155\n",
            "Epoch 15: val_accuracy did not improve from 0.74070\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.8587 - accuracy: 0.7155 - val_loss: 0.8519 - val_accuracy: 0.7135 - lr: 0.0010\n",
            "Epoch 16/30\n",
            "781/781 [============================>.] - ETA: 0s - loss: 0.8500 - accuracy: 0.7184\n",
            "Epoch 16: val_accuracy did not improve from 0.74070\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.8503 - accuracy: 0.7184 - val_loss: 0.7942 - val_accuracy: 0.7362 - lr: 0.0010\n",
            "Epoch 17/30\n",
            "782/781 [==============================] - ETA: 0s - loss: 0.8329 - accuracy: 0.7244\n",
            "Epoch 17: val_accuracy did not improve from 0.74070\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.8329 - accuracy: 0.7244 - val_loss: 1.0226 - val_accuracy: 0.7274 - lr: 0.0010\n",
            "Epoch 18/30\n",
            "781/781 [============================>.] - ETA: 0s - loss: 0.8137 - accuracy: 0.7293\n",
            "Epoch 18: val_accuracy did not improve from 0.74070\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.8140 - accuracy: 0.7292 - val_loss: 0.7856 - val_accuracy: 0.7385 - lr: 0.0010\n",
            "Epoch 19/30\n",
            "782/781 [==============================] - ETA: 0s - loss: 0.7493 - accuracy: 0.7539\n",
            "Epoch 19: val_accuracy improved from 0.74070 to 0.75940, saving model to best_model.h5\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.7493 - accuracy: 0.7539 - val_loss: 0.7275 - val_accuracy: 0.7594 - lr: 2.0000e-04\n",
            "Epoch 20/30\n",
            "782/781 [==============================] - ETA: 0s - loss: 0.7350 - accuracy: 0.7568\n",
            "Epoch 20: val_accuracy improved from 0.75940 to 0.76300, saving model to best_model.h5\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.7350 - accuracy: 0.7568 - val_loss: 0.7204 - val_accuracy: 0.7630 - lr: 2.0000e-04\n",
            "Epoch 21/30\n",
            "782/781 [==============================] - ETA: 0s - loss: 0.7258 - accuracy: 0.7606\n",
            "Epoch 21: val_accuracy did not improve from 0.76300\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.7258 - accuracy: 0.7606 - val_loss: 0.7234 - val_accuracy: 0.7621 - lr: 2.0000e-04\n",
            "Epoch 22/30\n",
            "782/781 [==============================] - ETA: 0s - loss: 0.7171 - accuracy: 0.7631\n",
            "Epoch 22: val_accuracy did not improve from 0.76300\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.7171 - accuracy: 0.7631 - val_loss: 0.7359 - val_accuracy: 0.7585 - lr: 2.0000e-04\n",
            "Epoch 23/30\n",
            "782/781 [==============================] - ETA: 0s - loss: 0.7074 - accuracy: 0.7674\n",
            "Epoch 23: val_accuracy improved from 0.76300 to 0.76570, saving model to best_model.h5\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.7074 - accuracy: 0.7674 - val_loss: 0.7055 - val_accuracy: 0.7657 - lr: 2.0000e-04\n",
            "Epoch 24/30\n",
            "782/781 [==============================] - ETA: 0s - loss: 0.7008 - accuracy: 0.7697\n",
            "Epoch 24: val_accuracy did not improve from 0.76570\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.7008 - accuracy: 0.7697 - val_loss: 0.7165 - val_accuracy: 0.7613 - lr: 2.0000e-04\n",
            "Epoch 25/30\n",
            "782/781 [==============================] - ETA: 0s - loss: 0.6904 - accuracy: 0.7712\n",
            "Epoch 25: val_accuracy did not improve from 0.76570\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.6904 - accuracy: 0.7712 - val_loss: 0.7300 - val_accuracy: 0.7626 - lr: 2.0000e-04\n",
            "Epoch 26/30\n",
            "782/781 [==============================] - ETA: 0s - loss: 0.6943 - accuracy: 0.7714\n",
            "Epoch 26: val_accuracy did not improve from 0.76570\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.6943 - accuracy: 0.7714 - val_loss: 0.7145 - val_accuracy: 0.7626 - lr: 2.0000e-04\n",
            "Epoch 27/30\n",
            "781/781 [============================>.] - ETA: 0s - loss: 0.6845 - accuracy: 0.7736\n",
            "Epoch 27: val_accuracy improved from 0.76570 to 0.76820, saving model to best_model.h5\n",
            "781/781 [==============================] - 39s 49ms/step - loss: 0.6845 - accuracy: 0.7736 - val_loss: 0.7034 - val_accuracy: 0.7682 - lr: 2.0000e-04\n",
            "Epoch 28/30\n",
            "782/781 [==============================] - ETA: 0s - loss: 0.6732 - accuracy: 0.7792\n",
            "Epoch 28: val_accuracy did not improve from 0.76820\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.6732 - accuracy: 0.7792 - val_loss: 0.7211 - val_accuracy: 0.7671 - lr: 2.0000e-04\n",
            "Epoch 29/30\n",
            "781/781 [============================>.] - ETA: 0s - loss: 0.6693 - accuracy: 0.7786\n",
            "Epoch 29: val_accuracy improved from 0.76820 to 0.76970, saving model to best_model.h5\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.6692 - accuracy: 0.7787 - val_loss: 0.7110 - val_accuracy: 0.7697 - lr: 2.0000e-04\n",
            "Epoch 30/30\n",
            "782/781 [==============================] - ETA: 0s - loss: 0.6691 - accuracy: 0.7785\n",
            "Epoch 30: val_accuracy did not improve from 0.76970\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.6691 - accuracy: 0.7785 - val_loss: 0.7143 - val_accuracy: 0.7649 - lr: 2.0000e-04\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.7143 - accuracy: 0.7649\n",
            "Test Accuracy: 0.7649000287055969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model-2**"
      ],
      "metadata": {
        "id": "yd9k75H_wiLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define CNN architecture\n",
        "model2 = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAl1wleOpl_5",
        "outputId": "7f6444d5-eb59-40cf-8907-a77c838c3e2a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 32, 32, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 32, 32, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_8 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_10 (Ba  (None, 8, 8, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_11 (Ba  (None, 8, 8, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 512)               1049088   \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1343018 (5.12 MB)\n",
            "Trainable params: 1342122 (5.12 MB)\n",
            "Non-trainable params: 896 (3.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model2.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model2.fit(train_images, train_labels, epochs=30, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model2.evaluate(test_images, test_labels)\n",
        "\n",
        "print(f\"Test Accuracy: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpOpUe_EnWMc",
        "outputId": "7b875761-ba33-44e5-d6f9-1da2b7a8f4f9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "313/313 [==============================] - 15s 30ms/step - loss: 1.7410 - accuracy: 0.3984 - val_loss: 3.3037 - val_accuracy: 0.2060\n",
            "Epoch 2/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 1.2510 - accuracy: 0.5529 - val_loss: 1.2707 - val_accuracy: 0.5583\n",
            "Epoch 3/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 1.0389 - accuracy: 0.6348 - val_loss: 0.9648 - val_accuracy: 0.6534\n",
            "Epoch 4/30\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 0.9024 - accuracy: 0.6856 - val_loss: 1.0912 - val_accuracy: 0.6513\n",
            "Epoch 5/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.8109 - accuracy: 0.7166 - val_loss: 0.7658 - val_accuracy: 0.7420\n",
            "Epoch 6/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.7428 - accuracy: 0.7418 - val_loss: 0.7501 - val_accuracy: 0.7421\n",
            "Epoch 7/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.6939 - accuracy: 0.7581 - val_loss: 0.6363 - val_accuracy: 0.7802\n",
            "Epoch 8/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.6447 - accuracy: 0.7765 - val_loss: 0.6693 - val_accuracy: 0.7759\n",
            "Epoch 9/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.5977 - accuracy: 0.7919 - val_loss: 0.6241 - val_accuracy: 0.7881\n",
            "Epoch 10/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.5641 - accuracy: 0.8041 - val_loss: 0.6382 - val_accuracy: 0.7852\n",
            "Epoch 11/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.5217 - accuracy: 0.8166 - val_loss: 0.6148 - val_accuracy: 0.7987\n",
            "Epoch 12/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.4999 - accuracy: 0.8256 - val_loss: 0.6725 - val_accuracy: 0.7897\n",
            "Epoch 13/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.4758 - accuracy: 0.8353 - val_loss: 0.5980 - val_accuracy: 0.8048\n",
            "Epoch 14/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.4516 - accuracy: 0.8425 - val_loss: 0.5372 - val_accuracy: 0.8228\n",
            "Epoch 15/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.4254 - accuracy: 0.8529 - val_loss: 0.6008 - val_accuracy: 0.8088\n",
            "Epoch 16/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.3968 - accuracy: 0.8632 - val_loss: 0.5473 - val_accuracy: 0.8249\n",
            "Epoch 17/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.3843 - accuracy: 0.8653 - val_loss: 0.5329 - val_accuracy: 0.8313\n",
            "Epoch 18/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.3622 - accuracy: 0.8731 - val_loss: 0.5736 - val_accuracy: 0.8224\n",
            "Epoch 19/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.3514 - accuracy: 0.8776 - val_loss: 0.5875 - val_accuracy: 0.8190\n",
            "Epoch 20/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.3311 - accuracy: 0.8870 - val_loss: 0.5737 - val_accuracy: 0.8250\n",
            "Epoch 21/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.3227 - accuracy: 0.8867 - val_loss: 0.6137 - val_accuracy: 0.8124\n",
            "Epoch 22/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.3012 - accuracy: 0.8953 - val_loss: 0.5498 - val_accuracy: 0.8368\n",
            "Epoch 23/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.2896 - accuracy: 0.8997 - val_loss: 0.5468 - val_accuracy: 0.8378\n",
            "Epoch 24/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.2741 - accuracy: 0.9016 - val_loss: 0.5184 - val_accuracy: 0.8426\n",
            "Epoch 25/30\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 0.2710 - accuracy: 0.9050 - val_loss: 0.6823 - val_accuracy: 0.8146\n",
            "Epoch 26/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.2595 - accuracy: 0.9107 - val_loss: 0.5460 - val_accuracy: 0.8419\n",
            "Epoch 27/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.2488 - accuracy: 0.9150 - val_loss: 0.5881 - val_accuracy: 0.8287\n",
            "Epoch 28/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.2496 - accuracy: 0.9123 - val_loss: 0.5062 - val_accuracy: 0.8482\n",
            "Epoch 29/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.2418 - accuracy: 0.9165 - val_loss: 0.5570 - val_accuracy: 0.8448\n",
            "Epoch 30/30\n",
            "313/313 [==============================] - 7s 23ms/step - loss: 0.2274 - accuracy: 0.9213 - val_loss: 0.5434 - val_accuracy: 0.8431\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5790 - accuracy: 0.8412\n",
            "Test Accuracy: 0.8411999940872192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SSTEPzjdnWGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model-3**"
      ],
      "metadata": {
        "id": "hr6voVsvyPqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MobileNetV2 as base model\n",
        "base_model = MobileNetV2(input_shape=(32, 32, 3), include_top=False, weights='imagenet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvWKVdhIwyDT",
        "outputId": "0fc50c23-c587-4803-cd31-22c8f30ba9a0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Add classification head\n",
        "model3 = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpDLWNWBwyBH",
        "outputId": "709be706-9c31-410b-fd7f-8852846d481e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_224 (Func  (None, 1, 1, 1280)        2257984   \n",
            " tional)                                                         \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 1280)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 512)               655872    \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 512)               2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 256)               1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 128)               512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3082954 (11.76 MB)\n",
            "Trainable params: 3047050 (11.62 MB)\n",
            "Non-trainable params: 35904 (140.25 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define learning rate schedule\n",
        "def lr_schedule(epoch):\n",
        "    if epoch < 10:\n",
        "        return 0.001\n",
        "    elif epoch < 20:\n",
        "        return 0.0005\n",
        "    else:\n",
        "        return 0.0001\n",
        "\n",
        "# Compile the model\n",
        "model3.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks\n",
        "callbacks = [LearningRateScheduler(lr_schedule)]\n",
        "\n",
        "# Train the model\n",
        "history = model3.fit(datagen.flow(train_images, train_labels, batch_size=64),\n",
        "                    steps_per_epoch=len(train_images) / 64,\n",
        "                    epochs=30,\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    callbacks=callbacks)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model3.evaluate(test_images, test_labels)\n",
        "\n",
        "print(f\"Test Accuracy: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hFHCbyMwx-g",
        "outputId": "e0b47cb4-ce3d-4e84-9028-7f195637083c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "781/781 [==============================] - 82s 68ms/step - loss: 2.0544 - accuracy: 0.3009 - val_loss: 2.0307 - val_accuracy: 0.2995 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "781/781 [==============================] - 52s 67ms/step - loss: 1.2791 - accuracy: 0.5662 - val_loss: 1.7144 - val_accuracy: 0.4550 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "781/781 [==============================] - 52s 67ms/step - loss: 1.0646 - accuracy: 0.6473 - val_loss: 1.3693 - val_accuracy: 0.5857 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "781/781 [==============================] - 54s 69ms/step - loss: 0.9812 - accuracy: 0.6788 - val_loss: 1.8129 - val_accuracy: 0.5761 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "781/781 [==============================] - 52s 67ms/step - loss: 0.9079 - accuracy: 0.7025 - val_loss: 1.0751 - val_accuracy: 0.7017 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "781/781 [==============================] - 53s 68ms/step - loss: 0.8713 - accuracy: 0.7188 - val_loss: 1.1367 - val_accuracy: 0.6925 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "781/781 [==============================] - 51s 66ms/step - loss: 0.8479 - accuracy: 0.7243 - val_loss: 1.2187 - val_accuracy: 0.6994 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "781/781 [==============================] - 52s 67ms/step - loss: 0.8163 - accuracy: 0.7361 - val_loss: 2.1141 - val_accuracy: 0.5648 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "781/781 [==============================] - 52s 66ms/step - loss: 0.7905 - accuracy: 0.7445 - val_loss: 1.2317 - val_accuracy: 0.7070 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "781/781 [==============================] - 52s 66ms/step - loss: 0.7708 - accuracy: 0.7510 - val_loss: 2.4231 - val_accuracy: 0.5423 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "781/781 [==============================] - 52s 67ms/step - loss: 0.6751 - accuracy: 0.7798 - val_loss: 1.2374 - val_accuracy: 0.7080 - lr: 5.0000e-04\n",
            "Epoch 12/30\n",
            "781/781 [==============================] - 52s 66ms/step - loss: 0.6386 - accuracy: 0.7917 - val_loss: 0.6885 - val_accuracy: 0.7912 - lr: 5.0000e-04\n",
            "Epoch 13/30\n",
            "781/781 [==============================] - 52s 66ms/step - loss: 0.6137 - accuracy: 0.8009 - val_loss: 0.6178 - val_accuracy: 0.8037 - lr: 5.0000e-04\n",
            "Epoch 14/30\n",
            "781/781 [==============================] - 51s 66ms/step - loss: 0.5994 - accuracy: 0.8051 - val_loss: 0.7791 - val_accuracy: 0.7623 - lr: 5.0000e-04\n",
            "Epoch 15/30\n",
            "781/781 [==============================] - 52s 67ms/step - loss: 0.5936 - accuracy: 0.8070 - val_loss: 0.5918 - val_accuracy: 0.8104 - lr: 5.0000e-04\n",
            "Epoch 16/30\n",
            "781/781 [==============================] - 52s 66ms/step - loss: 0.5780 - accuracy: 0.8117 - val_loss: 0.7071 - val_accuracy: 0.7954 - lr: 5.0000e-04\n",
            "Epoch 17/30\n",
            "781/781 [==============================] - 53s 68ms/step - loss: 0.5653 - accuracy: 0.8155 - val_loss: 0.7248 - val_accuracy: 0.7859 - lr: 5.0000e-04\n",
            "Epoch 18/30\n",
            "781/781 [==============================] - 52s 67ms/step - loss: 0.5642 - accuracy: 0.8169 - val_loss: 0.6668 - val_accuracy: 0.7960 - lr: 5.0000e-04\n",
            "Epoch 19/30\n",
            "781/781 [==============================] - 52s 67ms/step - loss: 0.5410 - accuracy: 0.8237 - val_loss: 0.5777 - val_accuracy: 0.8176 - lr: 5.0000e-04\n",
            "Epoch 20/30\n",
            "781/781 [==============================] - 51s 66ms/step - loss: 0.5354 - accuracy: 0.8270 - val_loss: 0.6843 - val_accuracy: 0.7980 - lr: 5.0000e-04\n",
            "Epoch 21/30\n",
            "781/781 [==============================] - 53s 67ms/step - loss: 0.4678 - accuracy: 0.8473 - val_loss: 0.4671 - val_accuracy: 0.8484 - lr: 1.0000e-04\n",
            "Epoch 22/30\n",
            "781/781 [==============================] - 50s 65ms/step - loss: 0.4452 - accuracy: 0.8545 - val_loss: 0.4436 - val_accuracy: 0.8527 - lr: 1.0000e-04\n",
            "Epoch 23/30\n",
            "781/781 [==============================] - 52s 66ms/step - loss: 0.4360 - accuracy: 0.8591 - val_loss: 0.4394 - val_accuracy: 0.8528 - lr: 1.0000e-04\n",
            "Epoch 24/30\n",
            "781/781 [==============================] - 52s 67ms/step - loss: 0.4279 - accuracy: 0.8599 - val_loss: 0.4481 - val_accuracy: 0.8524 - lr: 1.0000e-04\n",
            "Epoch 25/30\n",
            "781/781 [==============================] - 51s 65ms/step - loss: 0.4166 - accuracy: 0.8638 - val_loss: 0.4507 - val_accuracy: 0.8505 - lr: 1.0000e-04\n",
            "Epoch 26/30\n",
            "781/781 [==============================] - 50s 64ms/step - loss: 0.4127 - accuracy: 0.8638 - val_loss: 0.4299 - val_accuracy: 0.8572 - lr: 1.0000e-04\n",
            "Epoch 27/30\n",
            "781/781 [==============================] - 50s 64ms/step - loss: 0.4073 - accuracy: 0.8657 - val_loss: 0.4448 - val_accuracy: 0.8530 - lr: 1.0000e-04\n",
            "Epoch 28/30\n",
            "781/781 [==============================] - 50s 64ms/step - loss: 0.4047 - accuracy: 0.8665 - val_loss: 0.4507 - val_accuracy: 0.8510 - lr: 1.0000e-04\n",
            "Epoch 29/30\n",
            "781/781 [==============================] - 53s 68ms/step - loss: 0.4015 - accuracy: 0.8678 - val_loss: 0.4353 - val_accuracy: 0.8558 - lr: 1.0000e-04\n",
            "Epoch 30/30\n",
            "781/781 [==============================] - 51s 65ms/step - loss: 0.3917 - accuracy: 0.8717 - val_loss: 0.4517 - val_accuracy: 0.8503 - lr: 1.0000e-04\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.4517 - accuracy: 0.8503\n",
            "Test Accuracy: 0.8503000140190125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eQBRMHk8wx77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset\n",
        "(_, _), (test_images, test_labels) = cifar10.load_data()\n",
        "test_images = test_images.astype('float32') / 255.0\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=10)\n",
        "\n",
        "# Define models with their names\n",
        "models = [(model1, 'model1'), (model2, 'model2'), (model3, 'model3')]\n",
        "\n",
        "# Evaluate model function\n",
        "def evaluate_model(model, test_images, test_labels):\n",
        "    test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=0)\n",
        "    return test_acc\n",
        "\n",
        "# Evaluate models\n",
        "for model, name in models:\n",
        "    accuracy = evaluate_model(model, test_images, test_labels)\n",
        "    print(f\"{name}: Test Accuracy - {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyHTkchky0rM",
        "outputId": "4d856bbc-37bf-4846-f2cd-37ff98952bf0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model1: Test Accuracy - 76.49%\n",
            "model2: Test Accuracy - 84.12%\n",
            "model3: Test Accuracy - 85.03%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ILwxLZMy0od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TiFNnrkMy0lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ToTmhuhiy0Z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QntPjQ9iMDbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5rfs4rjjXP_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6NXaoRHZMDYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LZB9dPMMMDWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LGQOZoUWMDTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8XaPh18ZMDQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YdNwJV6wMDNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ngWFG8SACh4e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}